{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e89296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T06:38:35.137187Z",
     "iopub.status.busy": "2025-12-17T06:38:35.136886Z",
     "iopub.status.idle": "2025-12-17T06:38:35.921355Z",
     "shell.execute_reply": "2025-12-17T06:38:35.920101Z",
     "shell.execute_reply.started": "2025-12-17T06:38:35.137159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !mkdir -p /kaggle/working/image2biomassmodel/\n",
    "# !cp /kaggle/input/image2biomassmodelv1/pytorch/default/1/csiro_multitask_ckpt_2025-12-18.pt /kaggle/working/image2biomassmodel/csiro_multitask_ckpt_2025-12-18.pt\n",
    "# /kaggle/working/csiro_multitask_ckpt_2025-12-18.pt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98193882",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNetBackbone(nn.Module):\n",
    "    def __init__(self, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if pretrained:\n",
    "            w = models.ResNet18_Weights.DEFAULT\n",
    "        else:\n",
    "            w = None\n",
    "        \n",
    "        # use resnet18 instead of resnet34\n",
    "        m = models.resnet18(weights=w)\n",
    "\n",
    "        # ResNet stem + layers\n",
    "        self.conv1   = m.conv1\n",
    "        self.bn1     = m.bn1\n",
    "        self.relu    = m.relu\n",
    "        self.maxpool = m.maxpool\n",
    "        self.layer1  = m.layer1\n",
    "        self.layer2  = m.layer2\n",
    "        self.layer3  = m.layer3   # \"higher\" features\n",
    "        self.layer4  = m.layer4   # final features\n",
    "        self.avgpool = m.avgpool\n",
    "\n",
    "        # use the **last** block in each layer so it works for 18/34/etc.\n",
    "        self.out_dim_layer2 = m.layer2[-1].bn2.num_features\n",
    "        self.out_dim_layer3 = m.layer3[-1].bn2.num_features\n",
    "        self.out_dim_final  = m.fc.in_features  # 512 for resnet18\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x      = self.layer1(x)\n",
    "        feat_l2 = self.layer2(x)\n",
    "        feat_l3 = self.layer3(feat_l2)\n",
    "        feat_l4 = self.layer4(feat_l3)\n",
    "\n",
    "        # global pooling for final features\n",
    "        f_final = self.avgpool(feat_l4)\n",
    "        f_final = torch.flatten(f_final, 1)  # (B, 512)\n",
    "\n",
    "        return feat_l2, feat_l3, f_final\n",
    "    \n",
    "class Image2BiomassModel(nn.Module):\n",
    "    def __init__(self, num_species, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = ResNetBackbone(pretrained=pretrained)\n",
    "        \n",
    "        out_l2 = self.backbone.out_dim_layer2\n",
    "        out_l3 = self.backbone.out_dim_layer3\n",
    "        out_final = self.backbone.out_dim_final\n",
    "        \n",
    "      \n",
    "        def make_head_species(out_dim):\n",
    "            return nn.Sequential(\n",
    "            # nn.AdaptiveAvgPool2d(output_size=(1, 1)),   # pool layer3 to (B, 256, 1, 1)\n",
    "            # nn.Flatten(1),                              # (B, 256)\n",
    "                nn.Linear(in_features=out_final, out_features=256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.4), #\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(128, out_dim)\n",
    "            )\n",
    "            \n",
    "        def make_head_ndvi(out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(out_final, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(128, out_dim)\n",
    "            )\n",
    "        \n",
    "        def make_head_height(out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(out_final, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.3), # \n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2), # \n",
    "                nn.Linear(128, out_dim)\n",
    "            )\n",
    "            \n",
    "        def make_head_biomass(out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(out_final, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2), # \n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.1), # ++\n",
    "                nn.Linear(128, out_dim)\n",
    "            )\n",
    "        \n",
    "        def make_head_clover_p(out_dim):\n",
    "            # Clover presence (binary) -> output is a logit (no sigmoid here)\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(out_final, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(128, out_dim)\n",
    "            )\n",
    "\n",
    "        def make_head_clover_mag(out_dim):\n",
    "            # Clover magnitude (regression) -> predict same space as y (standardized log1p)\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(out_final, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(128, out_dim)\n",
    "            )\n",
    "\n",
    "        \n",
    "        # custome heads for Image2BiomassModel\n",
    "        self.head_species = make_head_species(num_species)      # Classfication\n",
    "        self.head_ndvi    = make_head_ndvi(1)                   # Regression\n",
    "        self.head_height  = make_head_height(1)                 # Regression\n",
    "        self.head_biomass    = make_head_biomass(4)     # Dead, Green, Total, GDM\n",
    "        self.head_clover_p   = make_head_clover_p(1)    # presence logit\n",
    "        self.head_clover_mag = make_head_clover_mag(1)  # magnitude\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_l2, out_l3, f_final = self.backbone(x)              # IN: torch.Size([1, 3, 256, 512]) -> OUT:\n",
    "        \n",
    "        out = {\n",
    "            \"species\"   : self.head_species(f_final),                  # (B,C)\n",
    "            \"ndvi\"      : self.head_ndvi(f_final).squeeze(-1),         # (B,)\n",
    "            \"height\"    : self.head_height(f_final).squeeze(-1),       # (B,)\n",
    "            \"biomass\"   : self.head_biomass(f_final),                  # (B,4)\n",
    "            \"clover_p_logit\"    : self.head_clover_p(f_final).squeeze(-1),   # (B,)\n",
    "            \"clover_mag\"        : self.head_clover_mag(f_final).squeeze(-1), # (B,)\n",
    "        }\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c08b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "TARGET_H, TARGET_W = 256, 512\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# optional torch versions (handy for unnormalize)\n",
    "IMAGENET_MEAN_T = torch.tensor(IMAGENET_MEAN).view(3,1,1)\n",
    "IMAGENET_STD_T  = torch.tensor(IMAGENET_STD).view(3,1,1)\n",
    "        \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_path, images_root, tfms=None):\n",
    "        self.df = pd.read_csv(csv_path).reset_index(drop=True)\n",
    "        self.images_root = images_root\n",
    "        \n",
    "        # simple test transforms (no random aug)\n",
    "        if tfms is None:\n",
    "            self.img_tfms = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Resize((TARGET_H, TARGET_W), interpolation=InterpolationMode.BICUBIC),\n",
    "                T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "            ])\n",
    "    \n",
    "    def _transform_image(self, img_path: Path) -> torch.Tensor:\n",
    "        img_bgr = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        if img_bgr is None:\n",
    "            raise FileNotFoundError(f\"Image not found or unreadable: {img_path}\")\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        return self.img_tfms(img_rgb)\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        # load image\n",
    "        img_path = f\"{self.images_root}/{row['image_path']}\"\n",
    "        img_t = self._transform_image(img_path)\n",
    "        \n",
    "        # which biomass component do we need for this row?\n",
    "        target_name = row[\"target_name\"]\n",
    "        sample_id = row[\"sample_id\"]\n",
    "        \n",
    "        return sample_id, target_name, img_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df22bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "@torch.inference_mode()\n",
    "def _inv_transform(col: str, x: torch.Tensor, state: dict) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x: tensor on standardized (and maybe log1p) scale -> returns raw scale tensor\n",
    "    \"\"\"\n",
    "    stats = state[\"stats\"]\n",
    "    cfg   = state.get(\"target_cfg\", {})\n",
    "\n",
    "    mu, sig = stats[col]\n",
    "    x = x * sig + mu\n",
    "\n",
    "    if cfg.get(col, {}).get(\"log1p\", False):\n",
    "        x = torch.expm1(x)\n",
    "        x = torch.clamp(x, min=0.0)\n",
    "\n",
    "    return x\n",
    "\n",
    "# -- Dataloader --\n",
    "test_ds = TestDataset(\n",
    "    csv_path=\"/kaggle/input/csiro-biomass/test.csv\",\n",
    "    images_root=\"/kaggle/input/csiro-biomass\"\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=16, num_workers=2, pin_memory=True, shuffle=False)\n",
    "\n",
    "# # -- Model -- \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ckpt_path = \"/kaggle/working/image2biomassmodel/csiro_multitask_ckpt_2025-12-17.pt\"\n",
    "ckpt_path = \"/kaggle/working/csiro_multitask_ckpt_2025-12-18.pt\"\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "state = ckpt[\"state\"]      # your preprocessing stats/config\n",
    "\n",
    "preds_rows = []\n",
    "\n",
    "# IMPORTANT: recreate the model architecture exactly like training\n",
    "model = Image2BiomassModel(num_species=16, pretrained=False).to(device)\n",
    "model.load_state_dict(ckpt[\"model_state\"], strict=True)\n",
    "model.to(device).eval()\n",
    "\n",
    "# --- Inference -- \n",
    "with torch.inference_mode():\n",
    "    for sids, target_nms, images in test_loader:\n",
    "        images = images.to(device=device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        # biomass head is now (B,4): [Dry_Dead_g, Dry_Green_g, Dry_Total_g, GDM_g]\n",
    "        preds_other = outputs[\"biomass\"]  # (B,4)\n",
    "\n",
    "        # clover two-part\n",
    "        clover_p   = torch.sigmoid(outputs[\"clover_p_logit\"])  # (B,)\n",
    "        clover_mag = outputs[\"clover_mag\"]                     # (B,) z-space\n",
    "        clover_raw_mag = _inv_transform(\"Dry_Clover_g\", clover_mag, state)  # (B,)\n",
    "        clover_raw = (clover_p * clover_raw_mag).clamp_min(0.0)            # (B,)\n",
    "\n",
    "        # map ONLY for the 4-dim head\n",
    "        name2idx_other = {\n",
    "            \"Dry_Dead_g\":  0,\n",
    "            \"Dry_Green_g\": 1,\n",
    "            \"Dry_Total_g\": 2,\n",
    "            \"GDM_g\":       3,\n",
    "        }\n",
    "\n",
    "        for i, (sid, tname) in enumerate(zip(sids, target_nms)):\n",
    "            if tname == \"Dry_Clover_g\":\n",
    "                value = float(clover_raw[i].item())\n",
    "            else:\n",
    "                col = name2idx_other[tname]\n",
    "                raw_pred = _inv_transform(tname, preds_other[i, col], state)  # scalar tensor\n",
    "                value = float(raw_pred.item())\n",
    "\n",
    "            preds_rows.append({\"sample_id\": sid, \"target\": value})\n",
    "  \n",
    "# data_root = \"/kaggle/input/csiro-biomass\"\n",
    "submit_csv_fl=\"submission.csv\"\n",
    "submission = pd.DataFrame(preds_rows)\n",
    "submission.to_csv(f\"{submit_csv_fl}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa3a2010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat submission.csv"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cv-dl-rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
