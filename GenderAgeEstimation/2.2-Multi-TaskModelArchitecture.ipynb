{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2705d671",
   "metadata": {},
   "source": [
    "## **2.2 Multi-Task Model Architecture**\n",
    "\n",
    "The model is formulated as a **multi-task learning system**, where a single shared representation supports multiple prediction objectives.\n",
    "\n",
    "### **2.2.2 Shared Backbone: The â€œMasterâ€ Feature Finder**\n",
    "\n",
    "The core of the architecture is a **ResNet-34 CNN** used as a **shared feature extractor** for all three tasks.\n",
    "\n",
    "Instead of training separate networks for age, gender, and race, the model first learns a strong, general-purpose **face representation**, which is then reused by task-specific heads.\n",
    "\n",
    "* **Input:** Preprocessed face images.\n",
    "* **Output:** A compact embedding capturing facial structure, texture, and shape.\n",
    "* **Benefit:** Since all tasks backpropagate through the same backbone, the learned representation generalizes across labels instead of overfitting to a single task.\n",
    "\n",
    "#### **2.2.2.1 The Inputâ€“Output Handshake**\n",
    "\n",
    "Before implementing task-specific logic, a strict contract is defined:\n",
    "\n",
    "* **Input:** A batch of face images resized and normalized to $(B, 3, 224, 224)$.\n",
    "* **Output:** A 512-dimensional embedding per image.\n",
    "* **Shape Guarantee:** A batch of size $B$ produces an output tensor of shape $(B, 512)$.\n",
    "\n",
    "This contract ensures that downstream heads can be attached cleanly and independently.\n",
    "\n",
    "#### **2.2.2.2 Surgery: Turning a Classifier into a Feature Finder**\n",
    "\n",
    "A standard ResNet-34 is trained to classify 1,000 ImageNet categories. These final class predictions are not useful for facial attribute learning.\n",
    "\n",
    "* **The Operation:** The final classification layer is removed.\n",
    "* **Stopping Point:** The network is truncated after the **Global Average Pooling** stage.\n",
    "* **Cleanup:** The pooled tensor $(B, 512, 1, 1)$ is flattened into a clean $(B, 512)$ embedding.\n",
    "\n",
    "This transforms ResNet-34 from an object classifier into a reusable feature extractor.\n",
    "\n",
    "#### **2.2.2.3 Training Strategy: Let the Backbone Learn**\n",
    "\n",
    "For the baseline model, the backbone is **fine-tuned**, not frozen.\n",
    "\n",
    "* **Full Gradient Flow:** All backbone parameters remain trainable.\n",
    "* **Shared Learning Signal:** Errors from age, gender, and race predictions all update the same representation.\n",
    "* **Result:** The backbone learns facial features that are broadly useful across tasks.\n",
    "\n",
    "#### **2.2.2.4 Trust-but-Verify Sanity Checks**\n",
    "\n",
    "Before large-scale training, two sanity checks validate correctness:\n",
    "\n",
    "1. **Shape Check:** A dummy input must produce exactly a 512-dimensional embedding.\n",
    "2. **Gradient Check:** A backward pass must propagate gradients into backbone parameters.\n",
    "\n",
    "These checks ensure the backbone is actively learning and not acting as a frozen observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b2f47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Literal\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ded2914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/83377.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/84431.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/682.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/5478.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/45214.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train/11276.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train/65931.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train/72645.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train/86050.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train/44783.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file    age  gender             race  service_test  split\n",
       "0  train/83377.jpg  50-59  Female           Indian         False  train\n",
       "1  train/84431.jpg  20-29    Male            Black          True  train\n",
       "2    train/682.jpg  20-29  Female  Latino_Hispanic          True  train\n",
       "3   train/5478.jpg  40-49    Male   Middle Eastern         False  train\n",
       "4  train/45214.jpg  30-39    Male  Southeast Asian         False  train\n",
       "5  train/11276.jpg  40-49    Male       East Asian          True  train\n",
       "6  train/65931.jpg  50-59  Female       East Asian          True  train\n",
       "7  train/72645.jpg  20-29  Female  Southeast Asian         False  train\n",
       "8  train/86050.jpg  10-19  Female           Indian         False  train\n",
       "9  train/44783.jpg  30-39  Female           Indian         False  train"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_train_df = pd.read_csv('/home/onkar/projects/data/fairface/splits/ff_train.csv')\n",
    "ff_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4326b89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/3285.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/8561.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val/2503.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/51659.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val/1482.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>val/7815.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>val/5324.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train/60461.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>True</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train/28122.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>False</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train/68788.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file    age  gender             race  service_test split\n",
       "0   train/3285.jpg  20-29  Female       East Asian         False   val\n",
       "1   train/8561.jpg  30-39    Male  Southeast Asian          True   val\n",
       "2     val/2503.jpg  20-29    Male  Southeast Asian          True   val\n",
       "3  train/51659.jpg  20-29    Male            White          True   val\n",
       "4     val/1482.jpg  10-19    Male  Southeast Asian         False   val\n",
       "5     val/7815.jpg  20-29  Female            White         False   val\n",
       "6     val/5324.jpg  40-49    Male            White         False   val\n",
       "7  train/60461.jpg  20-29  Female   Middle Eastern          True   val\n",
       "8  train/28122.jpg  50-59    Male  Latino_Hispanic         False   val\n",
       "9  train/68788.jpg  20-29  Female           Indian          True   val"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_valid_df = pd.read_csv('/home/onkar/projects/data/fairface/splits/ff_val.csv')\n",
    "ff_valid_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7796bbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val/8440.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/58829.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/25607.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/83916.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val/4051.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train/75496.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train/53677.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train/11646.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Male</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train/78166.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train/44393.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file    age  gender             race  service_test split\n",
       "0     val/8440.jpg  30-39  Female            White         False  test\n",
       "1  train/58829.jpg  20-29  Female            Black          True  test\n",
       "2  train/25607.jpg  30-39    Male       East Asian          True  test\n",
       "3  train/83916.jpg  30-39  Female            White         False  test\n",
       "4     val/4051.jpg    3-9    Male       East Asian          True  test\n",
       "5  train/75496.jpg  30-39  Female  Latino_Hispanic         False  test\n",
       "6  train/53677.jpg  30-39    Male            Black          True  test\n",
       "7  train/11646.jpg    3-9    Male           Indian         False  test\n",
       "8  train/78166.jpg    3-9  Female   Middle Eastern          True  test\n",
       "9  train/44393.jpg  30-39  Female            White         False  test"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_test_df = pd.read_csv('/home/onkar/projects/data/fairface/splits/ff_test.csv')\n",
    "ff_test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f1980",
   "metadata": {},
   "source": [
    "**The LabelEncoder:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf67619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.to_id: Dict[str, int] = {}\n",
    "        self.to_name: Dict[int, str] = {}\n",
    "\n",
    "    def fit(self, values) -> \"LabelEncoder\":\n",
    "        uniq = sorted(pd.Series(values).astype(str).unique().tolist())\n",
    "        self.to_id = {name: i for i, name in enumerate(uniq)}\n",
    "        self.to_name = {i: name for name, i in self.to_id.items()}\n",
    "        return self\n",
    "\n",
    "    def encode_one(self, v) -> int:\n",
    "        v = str(v)\n",
    "        if v not in self.to_id:\n",
    "            raise KeyError(f\"Unseen label '{v}' (not in train).\")\n",
    "        return self.to_id[v]\n",
    "\n",
    "@dataclass\n",
    "class FairFaceEncoders:\n",
    "    age: LabelEncoder\n",
    "    gender: LabelEncoder\n",
    "    race: LabelEncoder\n",
    "\n",
    "class FairFaceEncoderBuilder:\n",
    "    @staticmethod\n",
    "    def fit(train_df: pd.DataFrame) -> FairFaceEncoders:\n",
    "        return FairFaceEncoders(\n",
    "            age=LabelEncoder().fit(train_df[\"age\"]),\n",
    "            gender=LabelEncoder().fit(train_df[\"gender\"]),\n",
    "            race=LabelEncoder().fit(train_df[\"race\"]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf199b0",
   "metadata": {},
   "source": [
    "**FairFaceDataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37f4e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FairFaceDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        images_root: str | Path,\n",
    "        encoders,\n",
    "        *,\n",
    "        mode: Literal[\"train\", \"eval\"] = \"train\",\n",
    "        train_tfms=None,\n",
    "        eval_tfms=None,\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.root = Path(images_root)\n",
    "        self.enc = encoders\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in (\"train\", \"eval\"):\n",
    "            raise ValueError(f\"mode must be 'train' or 'eval', got: {self.mode!r}\")\n",
    "        if not self.root.exists():\n",
    "            raise FileNotFoundError(f\"images_root not found: {self.root}\")\n",
    "\n",
    "        required = {\"file\", \"age\", \"gender\", \"race\"}\n",
    "        missing = required - set(self.df.columns)\n",
    "        if missing:\n",
    "            raise KeyError(f\"Missing columns in df: {missing}. Have: {list(self.df.columns)}\")\n",
    "\n",
    "        # mode-specific transform requirement\n",
    "        if self.mode == \"train\":\n",
    "            if train_tfms is None:\n",
    "                raise ValueError(\"mode='train' requires train_tfms (cannot be None).\")\n",
    "            self.img_tfms = train_tfms\n",
    "        else:  # eval\n",
    "            if eval_tfms is None:\n",
    "                raise ValueError(\"mode='eval' requires eval_tfms (cannot be None).\")\n",
    "            self.img_tfms = eval_tfms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def _img_path(self, rel_path: str) -> Path:\n",
    "        return self.root / rel_path\n",
    "\n",
    "    def _transform_image(self, img_path: Path) -> torch.Tensor:\n",
    "        img_bgr = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        if img_bgr is None:\n",
    "            raise FileNotFoundError(f\"Image not found or unreadable: {img_path}\")\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        return self.img_tfms(img_rgb)  # exactly your pattern\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        rel_path = str(row[\"file\"])\n",
    "        img_path = self._img_path(rel_path)\n",
    "        img_t = self._transform_image(img_path)\n",
    "\n",
    "        y = {\n",
    "            \"age\": torch.tensor(self.enc.age.encode_one(row[\"age\"]), dtype=torch.long),\n",
    "            \"gender\": torch.tensor(self.enc.gender.encode_one(row[\"gender\"]), dtype=torch.long),\n",
    "            \"race\": torch.tensor(self.enc.race.encode_one(row[\"race\"]), dtype=torch.long),\n",
    "        }\n",
    "\n",
    "        meta = {\"file\": rel_path, \"path\": str(img_path), \"mode\": self.mode}\n",
    "        \n",
    "        return {\"img_t\": img_t, \"y\": y, \"meta\": meta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19d8f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SETUP: Paths, Data, and Encoders ====================\n",
    "from pathlib import Path\n",
    "\n",
    "TARGET_H, TARGET_W = 224, 224\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_root = Path(\"/home/onkar/projects/data/fairface\")\n",
    "splits_dir = data_root / \"splits\"\n",
    "\n",
    "ff_train_df = pd.read_csv(splits_dir / \"ff_train.csv\")\n",
    "ff_val_df   = pd.read_csv(splits_dir / \"ff_val.csv\")\n",
    "ff_test_df  = pd.read_csv(splits_dir / \"ff_test.csv\")\n",
    "\n",
    "encoders = FairFaceEncoderBuilder.fit(ff_train_df)\n",
    "\n",
    "# Standard evaluation transforms (no augmentation)\n",
    "eval_tfms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71e63422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Datasets created:\n",
      "  Train: 73273 samples\n",
      "  Valid: 14655 samples\n",
      "  Test:  9770 samples\n",
      "\n",
      "âœ“ DataLoaders created successfully!\n",
      "  train_loader: 286 batches\n",
      "  valid_loader: 57 batches\n",
      "  test_loader : 38 batches\n"
     ]
    }
   ],
   "source": [
    "# ==================== SETUP ALL COMPONENTS FOR DATASETS & DATALOADERS ====================\n",
    "\n",
    "# Step 0: Define DataLoader parameters\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "cpu_count = os.cpu_count() or 4\n",
    "optimal_num_workers = min(8, max(2, cpu_count - 2))\n",
    "\n",
    "common_params_optimized = {\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": optimal_num_workers,\n",
    "    \"pin_memory\": True,\n",
    "    \"persistent_workers\": True,\n",
    "    \"prefetch_factor\": 4,\n",
    "    \"drop_last\": True,\n",
    "}\n",
    "\n",
    "# Step 1: Define training transforms (Level 1 - recommended)\n",
    "train_tfms_selected = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# Step 2: Create datasets\n",
    "train_ds = FairFaceDataset(ff_train_df, data_root, encoders, mode=\"train\", train_tfms=train_tfms_selected)\n",
    "val_ds   = FairFaceDataset(ff_val_df,   data_root, encoders, mode=\"eval\",  eval_tfms=eval_tfms)\n",
    "test_ds  = FairFaceDataset(ff_test_df,  data_root, encoders, mode=\"eval\",  eval_tfms=eval_tfms)\n",
    "\n",
    "print(f\"âœ“ Datasets created:\")\n",
    "print(f\"  Train: {len(train_ds)} samples\")\n",
    "print(f\"  Valid: {len(val_ds)} samples\")\n",
    "print(f\"  Test:  {len(test_ds)} samples\")\n",
    "print()\n",
    "\n",
    "# Step 3: Create DataLoaders\n",
    "train_loader = DataLoader(train_ds, shuffle=True, **common_params_optimized)\n",
    "valid_loader = DataLoader(val_ds, shuffle=False, **common_params_optimized)\n",
    "test_loader  = DataLoader(test_ds,  shuffle=False, **common_params_optimized)\n",
    "\n",
    "print(\"âœ“ DataLoaders created successfully!\")\n",
    "print(f\"  train_loader: {len(train_loader)} batches\")\n",
    "print(f\"  valid_loader: {len(valid_loader)} batches\")\n",
    "print(f\"  test_loader : {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "551b75f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 16 CPUs, 12.0 GB available RAM\n",
      "Optimal num_workers: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== DATALOADER PERFORMANCE TUNING ====================\n",
    "# Optimal settings for modern GPUs with sufficient CPU cores\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "cpu_count = os.cpu_count() or 4\n",
    "available_memory_gb = psutil.virtual_memory().available / (1024**3)\n",
    "\n",
    "optimal_num_workers = min(8, max(2, cpu_count - 2))\n",
    "\n",
    "print(f\"System: {cpu_count} CPUs, {available_memory_gb:.1f} GB available RAM\")\n",
    "print(f\"Optimal num_workers: {optimal_num_workers}\")\n",
    "print()\n",
    "\n",
    "# Benchmark DataLoader parameters - DEFINE FIRST before using\n",
    "common_params_optimized = {\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": optimal_num_workers,\n",
    "    \"pin_memory\": True,\n",
    "    \"persistent_workers\": True,\n",
    "    \"prefetch_factor\": 4,\n",
    "    \"drop_last\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SELECTED: train_tfms_fast (Level 1 - Quick Wins)\n",
      "Expected speedup: ~15-20% with maintained accuracy\n",
      "============================================================\n",
      "\n",
      "To use faster versions, replace with:\n",
      "  - train_tfms_faster  : ~30-40% faster (fewer augmentations)\n",
      "  - train_tfms_fastest : ~50%+ faster (minimal augmentations, debug only)\n"
     ]
    }
   ],
   "source": [
    "# ==================== LEVEL 1: QUICK WINS (Fast) ====================\n",
    "# ~15-20% speedup: Lighter augmentations + higher prefetch\n",
    "train_tfms_fast = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(p=0.5),           # Keep (very cheap)\n",
    "    T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05),  # Reduce intensity\n",
    "    # REMOVE: RandomRotation (expensive)\n",
    "    # REMOVE: RandomAffine (expensive)\n",
    "    # REMOVE: RandomErasing (expensive)\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "\n",
    "train_tfms_faster = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.RandomRotation(degrees=10),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "train_tfms_selected = train_tfms_balanced  # USE THIS\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SELECTED: train_tfms_balanced (Level 1.5 - Anti-Overfitting)\")\n",
    "print(\"Stronger augmentations to combat overfitting\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e9d78",
   "metadata": {},
   "source": [
    "### ğŸš€ Performance Optimization: Fast Training Setup\n",
    "\n",
    "Three levels of optimizations for training speed:\n",
    "1. **Quick Wins** (~15-20% faster): Reduce augmentations, increase prefetch\n",
    "2. **Medium Effort** (~30-40% faster): Move heavy augments to GPU, optimize batch size\n",
    "3. **Max Speed** (~50%+ faster): Minimal augmentations + larger batch size (if memory allows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6847af4",
   "metadata": {},
   "source": [
    "### 2.2.2.1 Backbone interface (input -> embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bada809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "ResNet                                   [1, 3, 256, 512]          [1, 1000]                 --\n",
      "â”œâ”€Conv2d: 1-1                            [1, 3, 256, 512]          [1, 64, 128, 256]         9,408\n",
      "â”œâ”€BatchNorm2d: 1-2                       [1, 64, 128, 256]         [1, 64, 128, 256]         128\n",
      "â”œâ”€ReLU: 1-3                              [1, 64, 128, 256]         [1, 64, 128, 256]         --\n",
      "â”œâ”€MaxPool2d: 1-4                         [1, 64, 128, 256]         [1, 64, 64, 128]          --\n",
      "â”œâ”€Sequential: 1-5                        [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â””â”€BasicBlock: 2-1                   [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-1                  [1, 64, 64, 128]          [1, 64, 64, 128]          36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-2             [1, 64, 64, 128]          [1, 64, 64, 128]          128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-3                    [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-4                  [1, 64, 64, 128]          [1, 64, 64, 128]          36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-5             [1, 64, 64, 128]          [1, 64, 64, 128]          128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-6                    [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â””â”€BasicBlock: 2-2                   [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-7                  [1, 64, 64, 128]          [1, 64, 64, 128]          36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-8             [1, 64, 64, 128]          [1, 64, 64, 128]          128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-9                    [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-10                 [1, 64, 64, 128]          [1, 64, 64, 128]          36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-11            [1, 64, 64, 128]          [1, 64, 64, 128]          128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-12                   [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â””â”€BasicBlock: 2-3                   [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-13                 [1, 64, 64, 128]          [1, 64, 64, 128]          36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-14            [1, 64, 64, 128]          [1, 64, 64, 128]          128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-15                   [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-16                 [1, 64, 64, 128]          [1, 64, 64, 128]          36,864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-17            [1, 64, 64, 128]          [1, 64, 64, 128]          128\n",
      "â”‚    â”‚    â””â”€ReLU: 3-18                   [1, 64, 64, 128]          [1, 64, 64, 128]          --\n",
      "â”œâ”€Sequential: 1-6                        [1, 64, 64, 128]          [1, 128, 32, 64]          --\n",
      "â”‚    â””â”€BasicBlock: 2-4                   [1, 64, 64, 128]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-19                 [1, 64, 64, 128]          [1, 128, 32, 64]          73,728\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-20            [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-21                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-22                 [1, 128, 32, 64]          [1, 128, 32, 64]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-23            [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€Sequential: 3-24             [1, 64, 64, 128]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-1             [1, 64, 64, 128]          [1, 128, 32, 64]          8,192\n",
      "â”‚    â”‚    â”‚    â””â”€BatchNorm2d: 4-2        [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-25                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â””â”€BasicBlock: 2-5                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-26                 [1, 128, 32, 64]          [1, 128, 32, 64]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-27            [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-28                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-29                 [1, 128, 32, 64]          [1, 128, 32, 64]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-30            [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-31                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â””â”€BasicBlock: 2-6                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-32                 [1, 128, 32, 64]          [1, 128, 32, 64]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-33            [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-34                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-35                 [1, 128, 32, 64]          [1, 128, 32, 64]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-36            [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-37                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â””â”€BasicBlock: 2-7                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-38                 [1, 128, 32, 64]          [1, 128, 32, 64]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-39            [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-40                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-41                 [1, 128, 32, 64]          [1, 128, 32, 64]          147,456\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-42            [1, 128, 32, 64]          [1, 128, 32, 64]          256\n",
      "â”‚    â”‚    â””â”€ReLU: 3-43                   [1, 128, 32, 64]          [1, 128, 32, 64]          --\n",
      "â”œâ”€Sequential: 1-7                        [1, 128, 32, 64]          [1, 256, 16, 32]          --\n",
      "â”‚    â””â”€BasicBlock: 2-8                   [1, 128, 32, 64]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-44                 [1, 128, 32, 64]          [1, 256, 16, 32]          294,912\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-45            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-46                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-47                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-48            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€Sequential: 3-49             [1, 128, 32, 64]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-3             [1, 128, 32, 64]          [1, 256, 16, 32]          32,768\n",
      "â”‚    â”‚    â”‚    â””â”€BatchNorm2d: 4-4        [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-50                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â””â”€BasicBlock: 2-9                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-51                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-52            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-53                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-54                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-55            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-56                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â””â”€BasicBlock: 2-10                  [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-57                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-58            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-59                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-60                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-61            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-62                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â””â”€BasicBlock: 2-11                  [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-63                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-64            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-65                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-66                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-67            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-68                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â””â”€BasicBlock: 2-12                  [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-69                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-70            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-71                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-72                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-73            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-74                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â””â”€BasicBlock: 2-13                  [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-75                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-76            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-77                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-78                 [1, 256, 16, 32]          [1, 256, 16, 32]          589,824\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-79            [1, 256, 16, 32]          [1, 256, 16, 32]          512\n",
      "â”‚    â”‚    â””â”€ReLU: 3-80                   [1, 256, 16, 32]          [1, 256, 16, 32]          --\n",
      "â”œâ”€Sequential: 1-8                        [1, 256, 16, 32]          [1, 512, 8, 16]           --\n",
      "â”‚    â””â”€BasicBlock: 2-14                  [1, 256, 16, 32]          [1, 512, 8, 16]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-81                 [1, 256, 16, 32]          [1, 512, 8, 16]           1,179,648\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-82            [1, 512, 8, 16]           [1, 512, 8, 16]           1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-83                   [1, 512, 8, 16]           [1, 512, 8, 16]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-84                 [1, 512, 8, 16]           [1, 512, 8, 16]           2,359,296\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-85            [1, 512, 8, 16]           [1, 512, 8, 16]           1,024\n",
      "â”‚    â”‚    â””â”€Sequential: 3-86             [1, 256, 16, 32]          [1, 512, 8, 16]           --\n",
      "â”‚    â”‚    â”‚    â””â”€Conv2d: 4-5             [1, 256, 16, 32]          [1, 512, 8, 16]           131,072\n",
      "â”‚    â”‚    â”‚    â””â”€BatchNorm2d: 4-6        [1, 512, 8, 16]           [1, 512, 8, 16]           1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-87                   [1, 512, 8, 16]           [1, 512, 8, 16]           --\n",
      "â”‚    â””â”€BasicBlock: 2-15                  [1, 512, 8, 16]           [1, 512, 8, 16]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-88                 [1, 512, 8, 16]           [1, 512, 8, 16]           2,359,296\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-89            [1, 512, 8, 16]           [1, 512, 8, 16]           1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-90                   [1, 512, 8, 16]           [1, 512, 8, 16]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-91                 [1, 512, 8, 16]           [1, 512, 8, 16]           2,359,296\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-92            [1, 512, 8, 16]           [1, 512, 8, 16]           1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-93                   [1, 512, 8, 16]           [1, 512, 8, 16]           --\n",
      "â”‚    â””â”€BasicBlock: 2-16                  [1, 512, 8, 16]           [1, 512, 8, 16]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-94                 [1, 512, 8, 16]           [1, 512, 8, 16]           2,359,296\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-95            [1, 512, 8, 16]           [1, 512, 8, 16]           1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-96                   [1, 512, 8, 16]           [1, 512, 8, 16]           --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-97                 [1, 512, 8, 16]           [1, 512, 8, 16]           2,359,296\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-98            [1, 512, 8, 16]           [1, 512, 8, 16]           1,024\n",
      "â”‚    â”‚    â””â”€ReLU: 3-99                   [1, 512, 8, 16]           [1, 512, 8, 16]           --\n",
      "â”œâ”€AdaptiveAvgPool2d: 1-9                 [1, 512, 8, 16]           [1, 512, 1, 1]            --\n",
      "â”œâ”€Linear: 1-10                           [1, 512]                  [1, 1000]                 513,000\n",
      "===================================================================================================================\n",
      "Total params: 21,797,672\n",
      "Trainable params: 21,797,672\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 9.57\n",
      "===================================================================================================================\n",
      "Input size (MB): 1.57\n",
      "Forward/backward pass size (MB): 156.25\n",
      "Params size (MB): 87.19\n",
      "Estimated Total Size (MB): 245.01\n",
      "===================================================================================================================\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchinfo import summary\n",
    "\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "\n",
    "summary = summary(model, input_size=(1, 3, 256, 512), # (B, C, H, W)\n",
    "        col_names=(\"input_size\", \"output_size\", \"num_params\"),\n",
    "        depth=4)\n",
    "\n",
    "print(summary)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone34(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-34 backbone as a pure feature extractor.\n",
    "\n",
    "    Input : (B, 3, 224, 224)\n",
    "    Output: (B, 512)\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        weights = models.ResNet34_Weights.DEFAULT if pretrained else None\n",
    "        self.model = models.resnet34(weights=weights)\n",
    "\n",
    "        # Remove classifier\n",
    "        self.out_dim_final = self.model.fc.in_features  # 512\n",
    "        self.model.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)  # already (B, 512)\n",
    "\n",
    "class FairFaceMultiTaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-34 backbone + 3 classification heads (age / gender / race).\n",
    "    Uses final pooled embedding (B, 512) for all heads.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        num_age_classes: int = 9,\n",
    "        num_gender_classes: int = 2,\n",
    "        num_race_classes: int = 7,\n",
    "        pretrained: bool = True,\n",
    "        freeze_backbone: bool = False,\n",
    "        dropout_p: float = 0.3,  # INCREASE from 0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = ResNetBackbone34(pretrained=pretrained)\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        out_final = self.backbone.out_dim_final  # 512\n",
    "\n",
    "        # Optional shared projection (\"intermediate\") like your style\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(out_final, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "        )\n",
    "\n",
    "        # Heads output logits (no activation)\n",
    "        self.age_head = nn.Linear(512, num_age_classes)\n",
    "        self.gender_head = nn.Linear(512, num_gender_classes)\n",
    "        self.race_head = nn.Linear(512, num_race_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        f_final = self.backbone(x)  # f_final: (B, 512)\n",
    "\n",
    "        z = self.shared(f_final)\n",
    "\n",
    "        out = {\n",
    "            \"age\": self.age_head(z),\n",
    "            \"gender\": self.gender_head(z),\n",
    "            \"race\": self.race_head(z),\n",
    "        }\n",
    "\n",
    "        return out  # logits dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f2e91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_test_fairface_model(model: nn.Module, *, batch_size: int = 1, h: int = 224, w: int = 224, device=torch.device(\"cpu\")) -> None:\n",
    "    model = model.to(device).train()\n",
    "\n",
    "    # 1) Forward shape check\n",
    "    x = torch.randn(batch_size, 3, h, w, dtype=torch.float32, device=device)\n",
    "    out = model(x)\n",
    "\n",
    "    assert isinstance(out, dict), f\"Expected dict output, got {type(out)}\"\n",
    "    assert \"age\" in out and \"gender\" in out and \"race\" in out, f\"Missing keys: {out.keys()}\"\n",
    "\n",
    "    age_logits = out[\"age\"]\n",
    "    gender_logits = out[\"gender\"]\n",
    "    race_logits = out[\"race\"]\n",
    "\n",
    "    print(\"age logits   :\", tuple(age_logits.shape), age_logits.dtype)\n",
    "    print(\"gender logits:\", tuple(gender_logits.shape), gender_logits.dtype)\n",
    "    print(\"race logits  :\", tuple(race_logits.shape), race_logits.dtype)\n",
    "\n",
    "    # infer class counts from head modules (gold-standard, avoids hardcoding)\n",
    "    num_age = model.age_head.out_features\n",
    "    num_gender = model.gender_head.out_features\n",
    "    num_race = model.race_head.out_features\n",
    "\n",
    "    assert age_logits.shape == (batch_size, num_age)\n",
    "    assert gender_logits.shape == (batch_size, num_gender)\n",
    "    assert race_logits.shape == (batch_size, num_race)\n",
    "\n",
    "    # 2) Backward / gradient flow check (uses fake labels)\n",
    "    y_age = torch.randint(0, num_age, (batch_size,), device=device, dtype=torch.long)\n",
    "    y_gender = torch.randint(0, num_gender, (batch_size,), device=device, dtype=torch.long)\n",
    "    y_race = torch.randint(0, num_race, (batch_size,), device=device, dtype=torch.long)\n",
    "\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    loss = ce(age_logits, y_age) + ce(gender_logits, y_gender) + ce(race_logits, y_race)\n",
    "\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "\n",
    "    # confirm backbone gets gradients (at least one param)\n",
    "    got_grad = False\n",
    "    for p in model.backbone.parameters():\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            got_grad = True\n",
    "            break\n",
    "\n",
    "    print(\"loss:\", float(loss.detach().cpu()))\n",
    "    print(\"backbone received gradients:\", got_grad)\n",
    "\n",
    "    assert got_grad, \"Backbone did not receive gradients (check detach / freezing).\"\n",
    "\n",
    "    print(\"Sanity test passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dfb8fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age logits   : (1, 9) torch.float32\n",
      "gender logits: (1, 2) torch.float32\n",
      "race logits  : (1, 7) torch.float32\n",
      "loss: 4.936391830444336\n",
      "backbone received gradients: True\n",
      "Sanity test passed.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FairFaceMultiTaskModel(pretrained=True, freeze_backbone=False)\n",
    "sanity_test_fairface_model(model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da53428c",
   "metadata": {},
   "source": [
    "## ğŸ“Š Quick Reference: Training Speed Optimization\n",
    "\n",
    "### What Slows Down Training?\n",
    "\n",
    "| Factor | Bottleneck | Severity |\n",
    "|--------|-----------|----------|\n",
    "| **CPU Augmentations** | RandomRotation, RandomAffine, RandomErasing | ğŸ”´ HIGH |\n",
    "| **Image Decoding** | cv2.imread with num_workers | ğŸŸ¡ MEDIUM |\n",
    "| **Batch Transfer** | CPUâ†’GPU memory copy | ğŸŸ¡ MEDIUM |\n",
    "| **GPU Utilization** | Model size vs batch size mismatch | ğŸŸ¢ LOW |\n",
    "\n",
    "### Applied Optimizations\n",
    "\n",
    "âœ… **Batch 1: DataLoader**\n",
    "- Dynamic `num_workers` based on CPU count\n",
    "- `persistent_workers=True` (avoid restart overhead)\n",
    "- `prefetch_factor=4` (prefetch batches)\n",
    "- `pin_memory=True` (fast CPUâ†’GPU transfer)\n",
    "- `drop_last=True` (avoid partial batches)\n",
    "\n",
    "âœ… **Batch 2: Transforms (LEVEL 1)**\n",
    "- Removed RandomRotation, RandomAffine, RandomErasing\n",
    "- Kept RandomHorizontalFlip (negligible cost)\n",
    "- Reduced ColorJitter intensity\n",
    "- **Expected speedup: 15-20%**\n",
    "\n",
    "âœ… **Batch 3: GPU**\n",
    "- `torch.backends.cudnn.benchmark=True` (auto-tuning)\n",
    "- `torch.set_float32_matmul_precision(\"high\")` (Tensor Cores)\n",
    "\n",
    "### If Still Slow\n",
    "\n",
    "**Option A: More aggressive (LEVEL 2)**\n",
    "```python\n",
    "train_tfms_selected = train_tfms_faster  # Only horizontal flip\n",
    "# Expected: 30-40% faster\n",
    "```\n",
    "\n",
    "**Option B: Maximum speed (LEVEL 3 - debugging only)**\n",
    "```python\n",
    "train_tfms_selected = train_tfms_fastest  # No augmentations\n",
    "# Expected: 50%+ faster, but reduced regularization\n",
    "```\n",
    "\n",
    "**Option C: Hardware**\n",
    "- Increase `num_workers` (if CPU headroom exists)\n",
    "- Use faster storage (NVMe > SSD > HDD)\n",
    "- Increase batch size (if GPU memory allows)\n",
    "\n",
    "### Verify It Works\n",
    "\n",
    "Run the **DATALOADER SPEED BENCHMARK** cell above to see batch loading time. Target: **<50ms per batch**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-dl-rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
