{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9439d475",
   "metadata": {},
   "source": [
    "### 1. Import Model Architecture\n",
    "\n",
    "**Load dependencies**: Import the FairFaceMultiTaskModel, dataloaders, and encoders from notebook 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils.io import capture_output\n",
    "\n",
    "with capture_output() as cap:\n",
    "    %run \"2.2-Multi-TaskModelArchitecture.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f8fd2",
   "metadata": {},
   "source": [
    "### 2. Core Library Imports\n",
    "\n",
    "**Import libraries**: PyTorch, NumPy, Pandas, scikit-learn for model training, loss computation, and class weight calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Literal, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f337c",
   "metadata": {},
   "source": [
    "### 3. Helper Functions: Target Extraction\n",
    "\n",
    "**Purpose**: Normalize batch format handling - supports both dict and nested dict target structures.\n",
    "\n",
    "**Why needed**: DataLoader may return targets as `{\"age\": t, \"gender\": t, \"race\": t}` OR `{\"y\": {\"age\": t, ...}}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86980f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supports either:\n",
    "#     targets = {\"age\": t, \"gender\": t, \"race\": t}\n",
    "# or\n",
    "#     targets = {\"y\": {\"age\": t, \"gender\": t, \"race\": t}}\n",
    "def _extract_targets(targets: dict) -> dict:\n",
    "    if \"y\" in targets and isinstance(targets[\"y\"], dict):\n",
    "        t = targets[\"y\"]\n",
    "    else:\n",
    "        t = targets\n",
    "\n",
    "    return {\n",
    "        \"age\": t[\"age\"].long().view(-1),\n",
    "        \"gender\": t[\"gender\"].long().view(-1),\n",
    "        \"race\": t[\"race\"].long().view(-1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b74fb",
   "metadata": {},
   "source": [
    "### 3.1 Focal Loss Implementation\n",
    "\n",
    "**Focal Loss Formula**: \n",
    "\n",
    "$$FL(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t)$$\n",
    "\n",
    "**Components**:\n",
    "- **alpha_t (class weights)**: Handle statistical imbalance (rare vs frequent classes)\n",
    "- **focal term (1-p_t)^gamma**: Down-weight easy examples, focus on hard examples\n",
    "- **gamma=2.0**: Standard value from original paper (Lin et al., ICCV 2017)\n",
    "\n",
    "**Implementation notes**:\n",
    "- Applies label smoothing first via `F.cross_entropy`\n",
    "- Then applies focal modulation\n",
    "- Finally applies per-class weights if provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ee278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_ce(\n",
    "    logits: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    *,\n",
    "    gamma: float = 2.0,\n",
    "    class_weights: Optional[torch.Tensor] = None,\n",
    "    label_smoothing: float = 0.0,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Focal Loss (Lin et al., ICCV 2017) with optional per-class weighting.\n",
    "    FL(p_t) = -alpha_t * (1 - p_t)^gamma * log(p_t)\n",
    "\n",
    "    Notes:\n",
    "      - label_smoothing is applied via CE, then focal weighting is applied on top.\n",
    "      - class_weights is a tensor of shape (C,) on same device as logits.\n",
    "    \"\"\"\n",
    "    targets = targets.long().view(-1)\n",
    "\n",
    "    # per-sample CE (optionally smoothed)\n",
    "    ce = F.cross_entropy(logits, targets, reduction=\"none\", label_smoothing=label_smoothing)  # (B,)\n",
    "\n",
    "    # p_t for true class\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    pt = probs.gather(1, targets.unsqueeze(1)).squeeze(1).clamp_min(1e-8)  # (B,)\n",
    "\n",
    "    focal = (1.0 - pt) ** gamma\n",
    "\n",
    "    if class_weights is not None:\n",
    "        cw = class_weights.to(device=logits.device, dtype=logits.dtype)\n",
    "        alpha_t = cw.gather(0, targets)  # (B,)\n",
    "        loss = alpha_t * focal * ce\n",
    "    else:\n",
    "        loss = focal * ce\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06d0a4",
   "metadata": {},
   "source": [
    "### 3.2 Multi-Task Focal Loss\n",
    "\n",
    "**Strategy**: Apply focal loss independently to each task (age/gender/race), then sum.\n",
    "\n",
    "**Class weights**: Optional per-task weights dict with keys: age, gender, race\n",
    "\n",
    "**Returns**: Total loss (for backward) + per-task loss breakdown (for logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-task focal loss for FairFace:\n",
    "# preds: {\"age\": (B, A), \"gender\": (B, G), \"race\": (B, R)} logits\n",
    "# targets: {\"age\": (B,), \"gender\": (B,), \"race\": (B,)} (or wrapped under targets[\"y\"])\n",
    "def multitask_loss_focal(\n",
    "    preds: dict,\n",
    "    targets: dict,\n",
    "    *,\n",
    "    gamma: float = 2.0,\n",
    "    class_weights: Optional[dict] = None,\n",
    "    label_smoothing: float = 0.0,\n",
    "    task_loss_weights: Optional[dict] = None,\n",
    ") -> tuple[torch.Tensor, dict]:\n",
    "    t = _extract_targets(targets)\n",
    "\n",
    "    cw_age = class_weights.get(\"age\") if class_weights is not None else None\n",
    "    cw_gender = class_weights.get(\"gender\") if class_weights is not None else None\n",
    "    cw_race = class_weights.get(\"race\") if class_weights is not None else None\n",
    "\n",
    "    loss_age = focal_loss_ce(preds[\"age\"], t[\"age\"], gamma=gamma, class_weights=cw_age, label_smoothing=label_smoothing)\n",
    "    loss_gender = focal_loss_ce(preds[\"gender\"], t[\"gender\"], gamma=gamma, class_weights=cw_gender, label_smoothing=label_smoothing)\n",
    "    loss_race = focal_loss_ce(preds[\"race\"], t[\"race\"], gamma=gamma, class_weights=cw_race, label_smoothing=label_smoothing)\n",
    "\n",
    "    w_age = (task_loss_weights or {}).get(\"age\", 1.0)\n",
    "    w_gender = (task_loss_weights or {}).get(\"gender\", 1.0)\n",
    "    w_race = (task_loss_weights or {}).get(\"race\", 1.0)\n",
    "\n",
    "    total = w_age * loss_age + w_gender * loss_gender + w_race * loss_race\n",
    "\n",
    "    loss_parts = {\n",
    "        \"age\": loss_age.detach(),\n",
    "        \"gender\": loss_gender.detach(),\n",
    "        \"race\": loss_race.detach(),\n",
    "        \"total\": total.detach(),\n",
    "    }\n",
    "    return total, loss_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c874f088",
   "metadata": {},
   "source": [
    "### 3.3 Multi-Task Accuracy Computation\n",
    "\n",
    "**Computes**: Per-task classification accuracy + mean accuracy across all tasks.\n",
    "\n",
    "**Used for**: Training/validation monitoring without affecting gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def multitask_accuracies(preds: dict, targets: dict) -> dict:\n",
    "    t = _extract_targets(targets)\n",
    "    age_acc = (preds[\"age\"].argmax(dim=1) == t[\"age\"]).float().mean()\n",
    "    gender_acc = (preds[\"gender\"].argmax(dim=1) == t[\"gender\"]).float().mean()\n",
    "    race_acc = (preds[\"race\"].argmax(dim=1) == t[\"race\"]).float().mean()\n",
    "    mean_acc = (age_acc + gender_acc + race_acc) / 3.0\n",
    "    return {\"age\": age_acc, \"gender\": gender_acc, \"race\": race_acc, \"mean\": mean_acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c9e1c1",
   "metadata": {},
   "source": [
    "### 4. Training Loop: Batch Unpacking\n",
    "\n",
    "**Handles two batch formats**:\n",
    "1. Tuple: `(imgs, targets, meta)` from custom collate functions\n",
    "2. Dict: `{\"img_t\": imgs, \"y\": targets, \"meta\": meta}` from FairFaceDataset\n",
    "\n",
    "**Returns**: Images and targets on device, metadata stays on CPU (not needed for training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf23bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import nullcontext\n",
    "\n",
    "\n",
    "# Supports:\n",
    "#     A) batch = (imgs, targets, meta) from custom collate_fn\n",
    "#     B) batch = {\"img_t\": imgs, \"y\": targets, ...}\n",
    "# Returns:\n",
    "#     imgs:    (B,3,H,W) on device\n",
    "#     targets: dict of tensors on device (age/gender/race)\n",
    "#     meta:    whatever (kept on CPU)\n",
    "def _unpack_batch(batch, device):\n",
    "    if isinstance(batch, (tuple, list)) and len(batch) == 3:\n",
    "        imgs, targets, meta = batch\n",
    "    elif isinstance(batch, dict):\n",
    "        imgs = batch[\"img_t\"]\n",
    "        targets = batch.get(\"y\", batch)\n",
    "        meta = batch.get(\"meta\", None)\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported batch type: {type(batch)}\")\n",
    "\n",
    "    imgs = imgs.to(device, non_blocking=True)\n",
    "    t = _extract_targets(targets)\n",
    "    t = {k: v.to(device, non_blocking=True) for k, v in t.items()}\n",
    "    return imgs, t, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa56baf",
   "metadata": {},
   "source": [
    "### 4.1 Training Loop: One Epoch\n",
    "\n",
    "**Key features**:\n",
    "- **Mixed precision (AMP)**: Uses `torch.amp.autocast` for faster training on modern GPUs\n",
    "- **Focal loss**: Applies gamma focusing + optional class weights\n",
    "- **Label smoothing**: Regularization technique (default 0.05)\n",
    "- **Efficient gradient accumulation**: `set_to_none=True` for optimizer reset\n",
    "\n",
    "**Returns**: Epoch-averaged losses and accuracies (per-task + total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929734af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_fairface(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dl,\n",
    "    *,\n",
    "    gamma: float = 2.0,\n",
    "    class_weights: dict | None = None,\n",
    "    label_smoothing: float = 0.0,\n",
    "    task_loss_weights: dict | None = None,\n",
    "    grad_clip: float | None = 1.0,\n",
    "    device: torch.device,\n",
    "    scaler=None,\n",
    "    amp: bool = True,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    use_amp = bool(amp and device.type == \"cuda\")\n",
    "    autocast_cm = torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16) if use_amp else nullcontext()\n",
    "\n",
    "    total = 0\n",
    "    running_loss = {\"age\": 0.0, \"gender\": 0.0, \"race\": 0.0, \"total\": 0.0}\n",
    "    running_acc = {\"age\": 0.0, \"gender\": 0.0, \"race\": 0.0, \"mean\": 0.0}\n",
    "\n",
    "    for batch in train_dl:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        imgs, targets, _ = _unpack_batch(batch, device)\n",
    "\n",
    "        with autocast_cm:\n",
    "            preds = model(imgs)\n",
    "            total_loss, loss_parts = multitask_loss_focal(\n",
    "                preds,\n",
    "                targets,\n",
    "                gamma=gamma,\n",
    "                class_weights=class_weights,\n",
    "                label_smoothing=label_smoothing,\n",
    "                task_loss_weights=task_loss_weights,\n",
    "            )\n",
    "\n",
    "        if use_amp and scaler is not None:\n",
    "            scaler.scale(total_loss).backward()\n",
    "            if grad_clip is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            total_loss.backward()\n",
    "            if grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        total += bs\n",
    "\n",
    "        accs = multitask_accuracies(preds, targets)\n",
    "\n",
    "        running_loss[\"total\"] += float(total_loss.detach().item()) * bs\n",
    "        running_loss[\"age\"] += float(loss_parts[\"age\"].item()) * bs\n",
    "        running_loss[\"gender\"] += float(loss_parts[\"gender\"].item()) * bs\n",
    "        running_loss[\"race\"] += float(loss_parts[\"race\"].item()) * bs\n",
    "\n",
    "        running_acc[\"age\"] += float(accs[\"age\"].item()) * bs\n",
    "        running_acc[\"gender\"] += float(accs[\"gender\"].item()) * bs\n",
    "        running_acc[\"race\"] += float(accs[\"race\"].item()) * bs\n",
    "        running_acc[\"mean\"] += float(accs[\"mean\"].item()) * bs\n",
    "\n",
    "    train_losses = {k: v / total for k, v in running_loss.items()}\n",
    "    train_accs = {k: v / total for k, v in running_acc.items()}\n",
    "    return train_losses, train_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cebec5",
   "metadata": {},
   "source": [
    "### 4.2 Evaluation Loop: One Epoch\n",
    "\n",
    "**Differences from training**:\n",
    "- No gradient computation\n",
    "- Model in eval mode (disables dropout, batchnorm updates)\n",
    "- Typically uses `label_smoothing=0.0` for true performance measurement\n",
    "\n",
    "**Used for**: Validation during training, final test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a978d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def eval_one_epoch_fairface(\n",
    "    model,\n",
    "    eval_dl,\n",
    "    *,\n",
    "    gamma: float = 2.0,\n",
    "    class_weights: dict | None = None,\n",
    "    label_smoothing: float = 0.0,\n",
    "    task_loss_weights: dict | None = None,\n",
    "    device: torch.device,\n",
    "    amp: bool = True,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    use_amp = bool(amp and device.type == \"cuda\")\n",
    "    autocast_cm = torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16) if use_amp else nullcontext()\n",
    "\n",
    "    total = 0\n",
    "    running_loss = {\"age\": 0.0, \"gender\": 0.0, \"race\": 0.0, \"total\": 0.0}\n",
    "    running_acc = {\"age\": 0.0, \"gender\": 0.0, \"race\": 0.0, \"mean\": 0.0}\n",
    "\n",
    "    for batch in eval_dl:\n",
    "        imgs, targets, _ = _unpack_batch(batch, device)\n",
    "\n",
    "        with autocast_cm:\n",
    "            preds = model(imgs)\n",
    "            total_loss, loss_parts = multitask_loss_focal(\n",
    "                preds,\n",
    "                targets,\n",
    "                gamma=gamma,\n",
    "                class_weights=class_weights,\n",
    "                label_smoothing=label_smoothing,\n",
    "                task_loss_weights=task_loss_weights,\n",
    "            )\n",
    "            accs = multitask_accuracies(preds, targets)\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        total += bs\n",
    "\n",
    "        running_loss[\"total\"] += float(total_loss.item()) * bs\n",
    "        running_loss[\"age\"] += float(loss_parts[\"age\"].item()) * bs\n",
    "        running_loss[\"gender\"] += float(loss_parts[\"gender\"].item()) * bs\n",
    "        running_loss[\"race\"] += float(loss_parts[\"race\"].item()) * bs\n",
    "\n",
    "        running_acc[\"age\"] += float(accs[\"age\"].item()) * bs\n",
    "        running_acc[\"gender\"] += float(accs[\"gender\"].item()) * bs\n",
    "        running_acc[\"race\"] += float(accs[\"race\"].item()) * bs\n",
    "        running_acc[\"mean\"] += float(accs[\"mean\"].item()) * bs\n",
    "\n",
    "    valid_losses = {k: v / total for k, v in running_loss.items()}\n",
    "    valid_accs = {k: v / total for k, v in running_acc.items()}\n",
    "    return valid_losses, valid_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5a2c8",
   "metadata": {},
   "source": [
    "### 4.3 Full Training Loop (fit_fairface)\n",
    "\n",
    "**Orchestrates**:\n",
    "1. Train one epoch and compute train metrics\n",
    "2. Evaluate on validation set and compute val metrics\n",
    "3. Step learning rate scheduler (if provided)\n",
    "4. Log metrics and learning rate\n",
    "5. Store history for plotting\n",
    "\n",
    "**Scheduler handling**: Detects ReduceLROnPlateau automatically and passes validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2734bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_metrics(d, factor=1.0, precision=4):\n",
    "    return \", \".join(f\"{k}:{factor * float(v):3.{precision}f}\" for k, v in d.items())\n",
    "\n",
    "\n",
    "def fit_fairface(\n",
    "    model,\n",
    "    optimizer,\n",
    "    *,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    epochs: int,\n",
    "    sched=None,\n",
    "    gamma: float = 2.0,\n",
    "    class_weights: dict | None = None,\n",
    "    label_smoothing: float = 0.0,\n",
    "    task_loss_weights: dict | None = None,\n",
    "    grad_clip: float | None = 1.0,\n",
    "    device: torch.device,\n",
    "    amp: bool = True,\n",
    "):\n",
    "    scaler = torch.amp.GradScaler(enabled=(amp and device.type == \"cuda\"))\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"valid_loss\": [],\n",
    "        \"valid_acc\": [],\n",
    "        \"lr\": [],\n",
    "    }\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        train_losses, train_accs = train_one_epoch_fairface(\n",
    "            model,\n",
    "            optimizer,\n",
    "            train_dl,\n",
    "            gamma=gamma,\n",
    "            class_weights=class_weights,\n",
    "            label_smoothing=label_smoothing,\n",
    "            task_loss_weights=task_loss_weights,\n",
    "            grad_clip=grad_clip,\n",
    "            device=device,\n",
    "            scaler=scaler,\n",
    "            amp=amp,\n",
    "        )\n",
    "\n",
    "        valid_losses, valid_accs = eval_one_epoch_fairface(\n",
    "            model,\n",
    "            valid_dl,\n",
    "            gamma=gamma,\n",
    "            class_weights=class_weights,\n",
    "            label_smoothing=0.0,  # keep eval clean unless you explicitly want smoothing\n",
    "            task_loss_weights=task_loss_weights,\n",
    "            device=device,\n",
    "            amp=amp,\n",
    "        )\n",
    "\n",
    "        if sched is not None:\n",
    "            if \"plateau\" in sched.__class__.__name__.lower():\n",
    "                sched.step(valid_losses[\"total\"])\n",
    "            else:\n",
    "                sched.step()\n",
    "\n",
    "        curr_lr = float(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "        history[\"train_loss\"].append(train_losses)\n",
    "        history[\"train_acc\"].append(train_accs)\n",
    "        history[\"valid_loss\"].append(valid_losses)\n",
    "        history[\"valid_acc\"].append(valid_accs)\n",
    "        history[\"lr\"].append(curr_lr)\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {ep:02d}/{epochs:02d}]:\\n\"\n",
    "            f\"Train loss: {fmt_metrics(train_losses)} | \"\n",
    "            f\"Train acc: {fmt_metrics(train_accs, factor=100, precision=2)}\\n\"\n",
    "            f\"Valid loss: {fmt_metrics(valid_losses)} | \"\n",
    "            f\"Valid acc: {fmt_metrics(valid_accs, factor=100, precision=2)} | \"\n",
    "            f\"lr: {curr_lr:.8f}\"\n",
    "        )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f76c4",
   "metadata": {},
   "source": [
    "### 5. Model Setup\n",
    "\n",
    "**Architecture**: ResNet-34 backbone + 3 task-specific heads (age/gender/race)\n",
    "\n",
    "**Optimizer**: AdamW with lr=1e-4 (good default for fine-tuning pretrained models)\n",
    "\n",
    "**Scheduler**: ReduceLROnPlateau - reduces LR when validation loss plateaus\n",
    "\n",
    "**Loss config**:\n",
    "- `gamma=2.0`: Focal loss focusing parameter\n",
    "- `label_smoothing=0.05`: Prevents overconfident predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d496d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- device (single source of truth) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- model (create once, then move once) ---\n",
    "model = FairFaceMultiTaskModel(\n",
    "    pretrained=True, \n",
    "    freeze_backbone=False,\n",
    "    dropout_p=0.3  # INCREASED from 0.2\n",
    ").to(device)\n",
    "\n",
    "# --- loss config ---\n",
    "gamma = 2.0  # INCREASED from 1.5 (standard focal loss)\n",
    "label_smoothing = 0.1  # INCREASED from 0.05\n",
    "task_loss_weights = {\"age\": 1.2, \"gender\": 1.0, \"race\": 1.5}  # INCREASED race from 1.2\n",
    "grad_clip = 1.0\n",
    "\n",
    "# --- optimizer ---\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4  # ADDED (L2 regularization)\n",
    ")\n",
    "\n",
    "# --- scheduler ---\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    threshold=1e-3,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138cc004",
   "metadata": {},
   "source": [
    "### 5.1 Class Weight Computation Strategy\n",
    "\n",
    "**Weight type:** Inverse-frequency weights using sklearn's `class_weight=\"balanced\"` (higher weight for rarer classes).\n",
    "\n",
    "**Why from DataLoader (not DataFrame):**\n",
    "- Ensures weights match the encoded integer labels actually seen by the model\n",
    "- Handles any custom encoding/preprocessing automatically\n",
    "- Validates against the true batch distribution\n",
    "\n",
    "**Algorithm:**\n",
    "1. Infer number of classes from the model heads (no hardcoding)\n",
    "2. Collect all labels from the training DataLoader\n",
    "3. Compute balanced weights per task using sklearn's balanced mode\n",
    "4. Assign weight = 1.0 to any class not present in the sample\n",
    "5. Move all weight tensors to GPU once to avoid transfer overhead\n",
    "\n",
    "**Formula (per class $i$, per task):**\n",
    "\n",
    "$$\n",
    "w_i = \\frac{N_{\\text{total}}}{C \\cdot N_i}\n",
    "$$\n",
    "\n",
    "where $N_{\\text{total}}$ is the total number of samples for the task, $C$ is the number of classes, and $N_i$ is the sample count of class $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceef5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def _infer_num_classes_from_model(model) -> dict:\n",
    "    \"\"\"Infer number of classes from model head architecture.\"\"\"\n",
    "    return {\n",
    "        \"age\": model.age_head.out_features,\n",
    "        \"gender\": model.gender_head.out_features,\n",
    "        \"race\": model.race_head.out_features,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_class_weights_from_loader(train_dl, *, model, device: torch.device) -> dict:\n",
    "    \"\"\"\n",
    "    Compute balanced class weights from training DataLoader.\n",
    "    \n",
    "    Args:\n",
    "        train_dl: Training DataLoader\n",
    "        model: Model instance (to infer num_classes)\n",
    "        device: Target device for weight tensors\n",
    "    \n",
    "    Returns:\n",
    "        Dict mapping task -> torch.Tensor of weights (shape: [num_classes])\n",
    "    \"\"\"\n",
    "    num_classes = _infer_num_classes_from_model(model)\n",
    "    \n",
    "    # Collect all labels from training data\n",
    "    ys = {\"age\": [], \"gender\": [], \"race\": []}\n",
    "    \n",
    "    print(\"Collecting labels from training data...\")\n",
    "    for batch in train_dl:\n",
    "        # Handle both dict and tuple batch formats\n",
    "        if isinstance(batch, dict):\n",
    "            targets = batch.get(\"y\", batch)\n",
    "        elif isinstance(batch, (tuple, list)) and len(batch) >= 2:\n",
    "            _, targets = batch[:2]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        t = _extract_targets(targets)\n",
    "        for k in ys.keys():\n",
    "            ys[k].append(t[k].cpu().numpy())\n",
    "    \n",
    "    # Compute weights per task\n",
    "    out = {}\n",
    "    for task, chunks in ys.items():\n",
    "        y = np.concatenate(chunks, axis=0) if len(chunks) else np.array([], dtype=np.int64)\n",
    "        C = num_classes[task]\n",
    "        \n",
    "        # Initialize all weights to 1.0 (neutral)\n",
    "        w = np.ones((C,), dtype=np.float32)\n",
    "        \n",
    "        if y.size > 0:\n",
    "            present_classes = np.unique(y)\n",
    "            \n",
    "            # Compute balanced weights only for present classes\n",
    "            w_present = compute_class_weight(\n",
    "                class_weight=\"balanced\",\n",
    "                classes=present_classes,\n",
    "                y=y\n",
    "            ).astype(np.float32)\n",
    "            \n",
    "            w[present_classes] = w_present\n",
    "            \n",
    "            print(f\"{task:6s}: {C} classes | present: {len(present_classes)} | \"\n",
    "                  f\"weights range [{w.min():.3f}, {w.max():.3f}]\")\n",
    "        \n",
    "        out[task] = torch.tensor(w, dtype=torch.float32, device=device)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "# Compute class weights and move to device\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPUTING CLASS WEIGHTS FROM TRAINING DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class_weights = compute_class_weights_from_loader(train_loader, model=model, device=device)\n",
    "\n",
    "print(\"\\nâœ“ Class weights computed and moved to device!\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  Tasks: {list(class_weights.keys())}\")\n",
    "print(\"\\nWeights will be used in focal loss to handle class imbalance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58de2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- train (REDUCED epochs to stop overfitting) ---\n",
    "epochs = 10  # REDUCED from 15\n",
    "history = fit_fairface(\n",
    "    model,\n",
    "    optimizer,\n",
    "    sched=sched,\n",
    "    train_dl=train_loader,\n",
    "    valid_dl=valid_loader,\n",
    "    epochs=epochs,\n",
    "    gamma=gamma,\n",
    "    class_weights=class_weights,\n",
    "    label_smoothing=label_smoothing,\n",
    "    task_loss_weights=task_loss_weights,\n",
    "    grad_clip=grad_clip,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6990c",
   "metadata": {},
   "source": [
    "### 7. Training Visualization\n",
    "\n",
    "**Plots**:\n",
    "- **Row 1**: Per-task loss curves (age, gender, race)\n",
    "- **Row 2**: Per-task accuracy curves\n",
    "\n",
    "**What to look for**:\n",
    "- Train/val loss converging means good learning\n",
    "- Val loss increasing while train decreasing means overfitting\n",
    "- Consistent gap between train/val may need more regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f24f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects:\n",
    "# history[\"train_loss\"], history[\"valid_loss\"] : list[dict]\n",
    "# history[\"train_acc\"],  history[\"valid_acc\"]  : list[dict]\n",
    "# Each dict has per-task keys like: \"age\", \"gender\", \"race\"\n",
    "def plot_fairface_target_metrics(history, keys=(\"age\", \"gender\", \"race\")):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    # keep only keys that actually exist\n",
    "    existing = []\n",
    "    for k in keys:\n",
    "        if k in history[\"train_loss\"][0] and k in history[\"valid_loss\"][0]:\n",
    "            existing.append(k)\n",
    "\n",
    "    if not existing:\n",
    "        raise KeyError(f\"None of these keys found in history dicts: {keys}\")\n",
    "\n",
    "    n = len(existing)\n",
    "    fig, axes = plt.subplots(2, n, figsize=(6 * n, 8), constrained_layout=True)\n",
    "\n",
    "    # if n==1, axes is 1D in each row; normalize indexing\n",
    "    if n == 1:\n",
    "        axes = [axes[0:1], axes[1:2]]  # make it 2 x 1-like\n",
    "\n",
    "    # --- Row 1: Loss ---\n",
    "    for i, k in enumerate(existing):\n",
    "        ax = axes[0][i]\n",
    "        tr = [d[k] for d in history[\"train_loss\"]]\n",
    "        va = [d[k] for d in history[\"valid_loss\"]]\n",
    "        ax.plot(epochs, tr, label=\"Train loss\")\n",
    "        ax.plot(epochs, va, label=\"Valid loss\")\n",
    "        ax.set_title(f\"{k} loss\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    # --- Row 2: Accuracy ---\n",
    "    for i, k in enumerate(existing):\n",
    "        ax = axes[1][i]\n",
    "        tr = [d[k] * 100 for d in history[\"train_acc\"]]   # as %\n",
    "        va = [d[k] * 100 for d in history[\"valid_acc\"]]   # as %\n",
    "        ax.plot(epochs, tr, label=\"Train acc\")\n",
    "        ax.plot(epochs, va, label=\"Valid acc\")\n",
    "        ax.set_title(f\"{k} accuracy\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Accuracy (%)\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# usage\n",
    "plot_fairface_target_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ac093",
   "metadata": {},
   "source": [
    "### 8. Test Set Evaluation\n",
    "\n",
    "**Final performance measurement**:\n",
    "- Runs on held-out test set (never seen during training/validation)\n",
    "- Uses `label_smoothing=0.0` for true accuracy (no regularization)\n",
    "- Reports per-task accuracies + mean accuracy\n",
    "\n",
    "**This is the number you report**: Test accuracy represents real-world generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253524c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_losses, test_accs = eval_one_epoch_fairface(\n",
    "    model=model.to(device),\n",
    "    eval_dl=test_loader,\n",
    "    gamma=gamma,\n",
    "    class_weights=class_weights,\n",
    "    task_loss_weights=task_loss_weights,\n",
    "    device=device,\n",
    "    label_smoothing=0.0,\n",
    ")\n",
    "\n",
    "print(f\"Test total loss : {test_losses['total']:.4f}\")\n",
    "print(f\"Test mean acc   : {test_accs['mean']*100:.2f}%\")\n",
    "\n",
    "print(f\"Age acc         : {test_accs['age']*100:.2f}%\")\n",
    "print(f\"Gender acc      : {test_accs['gender']*100:.2f}%\")\n",
    "print(f\"Race acc        : {test_accs['race']*100:.2f}%\")\n",
    "\n",
    "print(\"Losses:\", {k: round(v, 4) for k, v in test_losses.items()})\n",
    "print(\"Accs  :\", {k: round(v*100, 2) for k, v in test_accs.items()})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-dl-rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
