{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bda0d41",
   "metadata": {},
   "source": [
    "## **2.3 Training Evaluation on Test Set**\n",
    "\n",
    "This section represents the final, unbiased evaluation of the trained system.\n",
    "\n",
    "The **Test Set** is a strict hold-out: it is never used during training or validation.\n",
    "\n",
    "### **2.3.1 Unseen Data Benchmark**\n",
    "\n",
    "The final model is evaluated on the held-out test split to measure generalization to previously unseen faces.\n",
    "\n",
    "### **2.3.2 Multi-Task Performance Breakdown**\n",
    "\n",
    "Performance is reported independently for:\n",
    "\n",
    "* **Age Classification**\n",
    "* **Gender Classification**\n",
    "* **Race Classification**\n",
    "\n",
    "This analysis verifies whether the shared backbone supports all tasks equally well.\n",
    "\n",
    "### **2.3.3 Fairness & Slice-Based Metrics**\n",
    "\n",
    "Accuracy is evaluated across demographic slices (e.g., per-race accuracy) to detect residual bias.\n",
    "\n",
    "### **2.3.4 Error Analysis via Confusion Matrices**\n",
    "\n",
    "Confusion matrices are used to visualize systematic errors, such as confusion between neighboring age bins.\n",
    "\n",
    "### **2.3.5 Identity Leakage Verification**\n",
    "\n",
    "Final checks confirm that no subject identities overlap between training/validation and test sets.\n",
    "\n",
    "### **2.3.6 Comparison to Commercial Baselines**\n",
    "\n",
    "Results are benchmarked against industry-standard commercial APIs to contextualize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8ce80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils.io import capture_output\n",
    "\n",
    "with capture_output() as cap:\n",
    "    %run \"2.2-Multi-TaskModelArchitecture.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a3951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Literal\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557e1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supports either:\n",
    "#     targets = {\"age\": t, \"gender\": t, \"race\": t}\n",
    "# or\n",
    "#     targets = {\"y\": {\"age\": t, \"gender\": t, \"race\": t}}\n",
    "def _extract_targets(targets: dict) -> dict:\n",
    "    if \"y\" in targets and isinstance(targets[\"y\"], dict):\n",
    "        t = targets[\"y\"]\n",
    "    else:\n",
    "        t = targets\n",
    "\n",
    "    return {\n",
    "        \"age\": t[\"age\"].long().view(-1),\n",
    "        \"gender\": t[\"gender\"].long().view(-1),\n",
    "        \"race\": t[\"race\"].long().view(-1),\n",
    "    }\n",
    "\n",
    "# Multi-task classification loss for FairFace:\n",
    "# preds: {\"age\": (B, A), \"gender\": (B, G), \"race\": (B, R)} logits\n",
    "# targets: {\"age\": (B,), \"gender\": (B,), \"race\": (B,)} (or wrapped under targets[\"y\"])\n",
    "def multitask_loss(preds: dict, targets: dict, *, weights: dict | None = None, label_smoothing: float = 0.0) -> tuple[torch.Tensor, dict]:\n",
    "    t = _extract_targets(targets)\n",
    "\n",
    "    w_age = 1.0\n",
    "    w_gender = 1.0\n",
    "    w_race = 1.0\n",
    "    if weights is not None:\n",
    "        w_age = float(weights.get(\"age\", 1.0))\n",
    "        w_gender = float(weights.get(\"gender\", 1.0))\n",
    "        w_race = float(weights.get(\"race\", 1.0))\n",
    "\n",
    "    loss_age = F.cross_entropy(preds[\"age\"], t[\"age\"], label_smoothing=label_smoothing)\n",
    "    loss_gender = F.cross_entropy(preds[\"gender\"], t[\"gender\"], label_smoothing=label_smoothing)\n",
    "    loss_race = F.cross_entropy(preds[\"race\"], t[\"race\"], label_smoothing=label_smoothing)\n",
    "\n",
    "    total = (w_age * loss_age) + (w_gender * loss_gender) + (w_race * loss_race)\n",
    "\n",
    "    loss_parts = {\n",
    "        \"age\": loss_age.detach(),\n",
    "        \"gender\": loss_gender.detach(),\n",
    "        \"race\": loss_race.detach(),\n",
    "    }\n",
    "    return total, loss_parts\n",
    "\n",
    "# Returns per-head accuracy + mean accuracy.\n",
    "@torch.inference_mode()\n",
    "def multitask_accuracies(preds: dict, targets: dict) -> dict:\n",
    "    t = _extract_targets(targets)\n",
    "\n",
    "    age_acc = (preds[\"age\"].argmax(dim=1) == t[\"age\"]).float().mean()\n",
    "    gender_acc = (preds[\"gender\"].argmax(dim=1) == t[\"gender\"]).float().mean()\n",
    "    race_acc = (preds[\"race\"].argmax(dim=1) == t[\"race\"]).float().mean()\n",
    "\n",
    "    mean_acc = (age_acc + gender_acc + race_acc) / 3.0\n",
    "\n",
    "    return {\n",
    "        \"age\": age_acc,\n",
    "        \"gender\": gender_acc,\n",
    "        \"race\": race_acc,\n",
    "        \"mean\": mean_acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6473611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import nullcontext\n",
    "\n",
    "\n",
    "# Supports:\n",
    "#     A) batch = (imgs, targets, meta) from custom collate_fn\n",
    "#     B) batch = {\"img_t\": imgs, \"y\": targets, ...}\n",
    "# Returns:\n",
    "#     imgs:    (B,3,H,W) on device\n",
    "#     targets: dict of tensors on device (age/gender/race)\n",
    "#     meta:    whatever (kept on CPU)\n",
    "def _unpack_batch(batch, device):\n",
    "    if isinstance(batch, (tuple, list)) and len(batch) == 3:\n",
    "        imgs, targets, meta = batch\n",
    "    elif isinstance(batch, dict):\n",
    "        imgs = batch[\"img_t\"]\n",
    "        targets = batch.get(\"y\", batch)  # if you stored targets directly\n",
    "        meta = batch.get(\"meta\", None)\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported batch type: {type(batch)}\")\n",
    "\n",
    "    imgs = imgs.to(device, non_blocking=True)\n",
    "\n",
    "    # move targets to device (each head target is (B,))\n",
    "    targets = {\n",
    "        \"age\": targets[\"age\"].to(device, non_blocking=True),\n",
    "        \"gender\": targets[\"gender\"].to(device, non_blocking=True),\n",
    "        \"race\": targets[\"race\"].to(device, non_blocking=True),\n",
    "    }\n",
    "\n",
    "    return imgs, targets, meta\n",
    "\n",
    "\n",
    "def train_one_epoch_fairface(model, optimizer, train_dl, *, label_smoothing: float = 0.0,\n",
    "                             device: torch.device = torch.device(\"cuda\"), scaler=None, amp: bool = True):\n",
    "    model.train()\n",
    "    \n",
    "    use_amp = amp and (device.type == \"cuda\")\n",
    "    autocast_cm = torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16) if use_amp else nullcontext()\n",
    "\n",
    "    total = 0\n",
    "    running_loss = {\"age\": 0.0, \"gender\": 0.0, \"race\": 0.0, \"total\": 0.0}\n",
    "    running_acc  = {\"age\": 0.0, \"gender\": 0.0, \"race\": 0.0, \"mean\": 0.0}\n",
    "\n",
    "    for batch in train_dl:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        imgs, targets, _ = _unpack_batch(batch, device)\n",
    "\n",
    "        with autocast_cm:\n",
    "            preds = model(imgs)  # {\"age\": logits, \"gender\": logits, \"race\": logits}\n",
    "            total_loss, loss_parts = multitask_loss(preds, targets, label_smoothing=label_smoothing)\n",
    "\n",
    "        if use_amp and scaler is not None:\n",
    "            scaler.scale(total_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        total += bs\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            accs = multitask_accuracies(preds, targets)\n",
    "\n",
    "        running_loss[\"total\"] += float(total_loss.detach().item()) * bs\n",
    "        running_loss[\"age\"]   += float(loss_parts[\"age\"].item()) * bs\n",
    "        running_loss[\"gender\"]+= float(loss_parts[\"gender\"].item()) * bs\n",
    "        running_loss[\"race\"]  += float(loss_parts[\"race\"].item()) * bs\n",
    "\n",
    "        running_acc[\"age\"]    += float(accs[\"age\"].item()) * bs\n",
    "        running_acc[\"gender\"] += float(accs[\"gender\"].item()) * bs\n",
    "        running_acc[\"race\"]   += float(accs[\"race\"].item()) * bs\n",
    "        running_acc[\"mean\"]   += float(accs[\"mean\"].item()) * bs\n",
    "\n",
    "    train_losses = {k: v / total for k, v in running_loss.items()}\n",
    "    train_accs   = {k: v / total for k, v in running_acc.items()}\n",
    "    return train_losses, train_accs\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_one_epoch_fairface(model, eval_dl, *, label_smoothing: float = 0.0,\n",
    "                            device: torch.device = torch.device(\"cuda\"), amp: bool = True):\n",
    "    model.eval()\n",
    "    \n",
    "    use_amp = amp and (device.type == \"cuda\")\n",
    "    autocast_cm = torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16) if use_amp else nullcontext()\n",
    "\n",
    "    total = 0\n",
    "    running_loss = {\"age\": 0.0, \"gender\": 0.0, \"race\": 0.0, \"total\": 0.0}\n",
    "    running_acc  = {\"age\": 0.0, \"gender\": 0.0, \"race\": 0.0, \"mean\": 0.0}\n",
    "\n",
    "    for batch in eval_dl:\n",
    "        imgs, targets, _ = _unpack_batch(batch, device)\n",
    "\n",
    "        with autocast_cm:\n",
    "            preds = model(imgs)\n",
    "            total_loss, loss_parts = multitask_loss(preds, targets, label_smoothing=label_smoothing)\n",
    "            accs = multitask_accuracies(preds, targets)\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        total += bs\n",
    "\n",
    "        running_loss[\"total\"] += float(total_loss.item()) * bs\n",
    "        running_loss[\"age\"]   += float(loss_parts[\"age\"].item()) * bs\n",
    "        running_loss[\"gender\"]+= float(loss_parts[\"gender\"].item()) * bs\n",
    "        running_loss[\"race\"]  += float(loss_parts[\"race\"].item()) * bs\n",
    "\n",
    "        running_acc[\"age\"]    += float(accs[\"age\"].item()) * bs\n",
    "        running_acc[\"gender\"] += float(accs[\"gender\"].item()) * bs\n",
    "        running_acc[\"race\"]   += float(accs[\"race\"].item()) * bs\n",
    "        running_acc[\"mean\"]   += float(accs[\"mean\"].item()) * bs\n",
    "\n",
    "    valid_losses = {k: v / total for k, v in running_loss.items()}\n",
    "    valid_accs   = {k: v / total for k, v in running_acc.items()}\n",
    "    \n",
    "    return valid_losses, valid_accs\n",
    "\n",
    "\n",
    "def fmt_metrics(d, factor=1.0, precision=4):\n",
    "    return \", \".join(f\"{k}:{factor * float(v):3.{precision}f}\" for k, v in d.items())\n",
    "\n",
    "\n",
    "def fit_fairface(model, optimizer, *, sched=None, train_dl=None, valid_dl=None, epochs: int = 25,\n",
    "                 label_smoothing: float = 0.0, device: torch.device = torch.device(\"cuda\"), amp: bool = True):\n",
    "    \n",
    "    scaler = torch.amp.GradScaler(enabled=(amp and device.type == \"cuda\"))\n",
    "    \n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"valid_loss\": [],\n",
    "        \"valid_acc\": [],\n",
    "        \"lr\": [],\n",
    "    }\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        train_losses, train_accs = train_one_epoch_fairface(\n",
    "            model, optimizer, train_dl,\n",
    "            label_smoothing=label_smoothing,\n",
    "            device=device, scaler=scaler, amp=amp)\n",
    "        \n",
    "        valid_losses, valid_accs = eval_one_epoch_fairface(\n",
    "            model, valid_dl,\n",
    "            label_smoothing=label_smoothing,\n",
    "            device=device, amp=amp\n",
    "        )\n",
    "\n",
    "        if sched is not None:\n",
    "            # standard: if ReduceLROnPlateau -> step on validation total loss\n",
    "            if \"plateau\" in sched.__class__.__name__.lower():\n",
    "                sched.step(valid_losses[\"total\"])\n",
    "            else:\n",
    "                sched.step()\n",
    "\n",
    "        curr_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        history[\"train_loss\"].append(train_losses)\n",
    "        history[\"train_acc\"].append(train_accs)\n",
    "        history[\"valid_loss\"].append(valid_losses)\n",
    "        history[\"valid_acc\"].append(valid_accs)\n",
    "        history[\"lr\"].append(curr_lr)\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {ep:02d}/{epochs:02d}]:\\n\"\n",
    "            f\"Train loss: {fmt_metrics(train_losses)} | \"\n",
    "            f\"Train acc: {fmt_metrics(train_accs, factor=100, precision=2)}\\n\"\n",
    "            f\"Valid loss: {fmt_metrics(valid_losses)} | \"\n",
    "            f\"Valid acc: {fmt_metrics(valid_accs, factor=100, precision=2)} | \"\n",
    "            f\"lr: {curr_lr:.8f}\"\n",
    "        )\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d496d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- device (single source of truth) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- model (create once, then move once) ---\n",
    "model = FairFaceMultiTaskModel(pretrained=True, freeze_backbone=False).to(device)\n",
    "\n",
    "# --- loss config ---\n",
    "label_smoothing = 0.05  # set 0.0 if you don't want it\n",
    "\n",
    "# --- optimizer ---\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# --- scheduler ---\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    threshold=1e-3,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # faster for fixed image sizes\n",
    "torch.set_float32_matmul_precision(\"high\")  # can help on Ampere+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58de2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01/15]:\n",
      "Train loss: age:1.3828, gender:0.3504, race:1.2657, total:2.9989 | Train acc: age:47.83, gender:86.81, race:55.10, mean:63.25\n",
      "Valid loss: age:1.2742, gender:0.2805, race:1.0694, total:2.6242 | Valid acc: age:51.84, gender:91.01, race:64.22, mean:69.02 | lr: 0.00010000\n",
      "[Epoch 02/15]:\n",
      "Train loss: age:1.1665, gender:0.2573, race:0.9882, total:2.4120 | Train acc: age:56.94, gender:92.80, race:68.03, mean:72.59\n",
      "Valid loss: age:1.1666, gender:0.2597, race:1.0160, total:2.4423 | Valid acc: age:56.38, gender:92.32, race:66.54, mean:71.75 | lr: 0.00010000\n",
      "[Epoch 03/15]:\n",
      "Train loss: age:1.0950, gender:0.2300, race:0.8893, total:2.2142 | Train acc: age:60.56, gender:94.34, race:72.73, mean:75.88\n",
      "Valid loss: age:1.1629, gender:0.2485, race:0.9826, total:2.3940 | Valid acc: age:56.78, gender:93.05, race:68.11, mean:72.65 | lr: 0.00010000\n",
      "[Epoch 04/15]:\n",
      "Train loss: age:1.0322, gender:0.2099, race:0.8097, total:2.0518 | Train acc: age:63.95, gender:95.54, race:76.57, mean:78.69\n",
      "Valid loss: age:1.1603, gender:0.2536, race:0.9880, total:2.4019 | Valid acc: age:57.22, gender:92.94, race:68.12, mean:72.76 | lr: 0.00010000\n"
     ]
    }
   ],
   "source": [
    "# --- train ---\n",
    "epochs = 15\n",
    "history = fit_fairface(\n",
    "    model,\n",
    "    optimizer,\n",
    "    sched=sched,\n",
    "    train_dl=train_loader,\n",
    "    valid_dl=valid_loader,\n",
    "    epochs=epochs,\n",
    "    label_smoothing=label_smoothing,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b50478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects:\n",
    "# history[\"train_loss\"], history[\"valid_loss\"] : list[dict]\n",
    "# history[\"train_acc\"],  history[\"valid_acc\"]  : list[dict]\n",
    "# Each dict has per-task keys like: \"age\", \"gender\", \"race\"\n",
    "def plot_fairface_target_metrics(history, keys=(\"age\", \"gender\", \"race\")):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    # keep only keys that actually exist\n",
    "    existing = []\n",
    "    for k in keys:\n",
    "        if k in history[\"train_loss\"][0] and k in history[\"valid_loss\"][0]:\n",
    "            existing.append(k)\n",
    "\n",
    "    if not existing:\n",
    "        raise KeyError(f\"None of these keys found in history dicts: {keys}\")\n",
    "\n",
    "    n = len(existing)\n",
    "    fig, axes = plt.subplots(2, n, figsize=(6 * n, 8), constrained_layout=True)\n",
    "\n",
    "    # if n==1, axes is 1D in each row; normalize indexing\n",
    "    if n == 1:\n",
    "        axes = [axes[0:1], axes[1:2]]  # make it 2 x 1-like\n",
    "\n",
    "    # --- Row 1: Loss ---\n",
    "    for i, k in enumerate(existing):\n",
    "        ax = axes[0][i]\n",
    "        tr = [d[k] for d in history[\"train_loss\"]]\n",
    "        va = [d[k] for d in history[\"valid_loss\"]]\n",
    "        ax.plot(epochs, tr, label=\"Train loss\")\n",
    "        ax.plot(epochs, va, label=\"Valid loss\")\n",
    "        ax.set_title(f\"{k} loss\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    # --- Row 2: Accuracy ---\n",
    "    for i, k in enumerate(existing):\n",
    "        ax = axes[1][i]\n",
    "        tr = [d[k] * 100 for d in history[\"train_acc\"]]   # as %\n",
    "        va = [d[k] * 100 for d in history[\"valid_acc\"]]   # as %\n",
    "        ax.plot(epochs, tr, label=\"Train acc\")\n",
    "        ax.plot(epochs, va, label=\"Valid acc\")\n",
    "        ax.set_title(f\"{k} accuracy\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Accuracy (%)\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# usage\n",
    "plot_fairface_target_metrics(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253524c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_losses, test_accs = eval_one_epoch_fairface(\n",
    "    model=model.to(device),\n",
    "    eval_dl=test_loader,\n",
    "    device=device,\n",
    "    label_smoothing=0.0,  # keep 0.0 for eval/test\n",
    ")\n",
    "\n",
    "print(f\"Test total loss : {test_losses['total']:.4f}\")\n",
    "print(f\"Test mean acc   : {test_accs['mean']*100:.2f}%\")\n",
    "\n",
    "print(f\"Age acc         : {test_accs['age']*100:.2f}%\")\n",
    "print(f\"Gender acc      : {test_accs['gender']*100:.2f}%\")\n",
    "print(f\"Race acc        : {test_accs['race']*100:.2f}%\")\n",
    "\n",
    "print(\"Losses:\", {k: round(v, 4) for k, v in test_losses.items()})\n",
    "print(\"Accs  :\", {k: round(v*100, 2) for k, v in test_accs.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570c53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-dl-rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
